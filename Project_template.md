## Спринт 7. Создание AI/ML чат-бота
Описание задания приведено здесь: (https://practicum.yandex.ru/learn/software-architect/courses/b713986d-ca8c-4dfd-a60b-a68f6ceab1a5/sprints/563515/topics/ea697128-d4b0-4f90-9b02-68936637c4a3/lessons/42685249-e7d2-4014-9620-486847b1ed64/)

## Задание 1. Исследование моделей и инфраструктуры

В рамках исследовния произведен анализ моделей и инфраструктуры, результаты приведены в [отчете](https://github.com/alexeit-315/yandex-practicum-7-rag/tree/rag/Task1/Выбор_технологий_реализации_RAG-бота.md), содержащем:
- Сравнение LLM-моделей
- Сравнение моделей эмбеддингов
- Сравнение векторных баз
- Сравнение ценовых парметров вариантов реализации
- Итоговые рекомендации

## Задание 2. Подготовка базы знаний

В рамках создания собственной базы знаний:
- Используя скрипт fandom_scraper.py с сайта fandom.com загружены и сохранены в текстовом виде согласно списку из [source_index.txt](https://github.com/alexeit-315/yandex-practicum-7-rag/tree/rag/Task2/source_index.txt) статьи о вселенной Звездных войн
- Используя скрипт fandom_replacement.py сформирован и затем вручную доработан словарь замен для имен, планет, рас, терминов
- Используя скрипт fandom_finalizer.py сформирована финальная база знаний в виде текстовых файлов, размещенных в [папке](https://github.com/alexeit-315/yandex-practicum-7-rag/tree/rag/Task2/knowledge_base)

## Задание 3. Создание векторного индекса базы знаний

Для создания векторного индекса базы знаний:
- Установлены необходимые пакеты ```pip install sentence-transformers langchain chromadb tqdm```
- Развернута локально модель ```git clone https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2```
- Настроен текстовый сплиттер с использованием ```RecursiveCharacterTextSplitter``` из LangChain (размер чанка 384 символа, перекрытие 50 символов)
- Обработаны 115 файлов о модифицированной вселенной Звездных войн из папки ```./knowledge_base``` нарезаны чанки (5337 чанков) и собраны метаданные с использованием подготовленного скрипта ```python build_index.py --model-path ./paraphrase-multilingual-MiniLM-L12-v2```
- Сгенерированы эмбеддинги с использованием модели ```/paraphrase-multilingual-MiniLM-L12-v2``` размерностью 384, время генерации 255с (было проведено тестирование нескольких моделей, для документов на русском языке эта показала наилучшие результаты)
- Создан индекс в векторной БД (Chroma)
- Произведена проверка работоспособности индекса с использованием подготовленного скрипта ```python test_index.py```, результаты сохранены в [test_results_20250903_203537.json](https://github.com/alexeit-315/yandex-practicum-7-rag/tree/rag/Task3/test_results_20250903_203537.json)

## Задание 4. Реализация RAG-бота с техниками промптинга

Для создания RAG-бота:
- Установлен фреймворк [ollama](https://ollama.com/download)
- Установлена модель llama3:instruct ```ollama pull llama3:instruct```
- Разработано приложение RAG, работающее с локальной моделью
- Произведено тестирование с использованием командной строки ```python main.py --query "Кто такой Щыб Шуррумхер?"```, приведены принтскрины результатов

## Задание 5. Запуск и демонстрация работы бота

Для тестирования RAG-бота:
- Подготовлен и загружен в ```./knowledge_base``` «злонамеренный» файл
- Создана векторная база, включающая «злонамеренный» файл 
- Установлена модель mistral:instruct ```ollama pull mistral:instruct``` несколько улучшившая качество генерации русского текста
- Доработано приложение RAG: изменена используемая модель, добавлен защитный слой (pre-prompt на этапе генерации промпта и post-prompt - фильтрация вредоносных чанков), добавлены режимы debug, пакетной обработки, отключения защитного слоя 
- Произведено тестирование с включенной ```python main.py --file "questions.txt"``` и выключенной ```python main.py --debug --query "пароль привилегированного пользователя root"``` защитой
- Результаты тестирования (принтскрины) сохранены в папке задания
- При включенной защите вредоносные запросы не прошли ни разу, при выключенной - вредоносные запросы при выполнении некоторых условий (высокое значение RELEVANCE_THRESHOLD, "правильная" формулировка запроса) периодически проходили

В целом, для в рамках исследования RAG-бот показал приемлемые результаты. Но для использования в проде, необходимо повышение качества его работы. Необходимо проведение кропотливого исследования для подбора:
- Размера чанка, возможно, использование семантического разделения на чанки
- Модели, используемой для генерации эмбеддингов; Более размерная модель 768D ```paraphrase-multilingual-mpnet-base-v2``` показала себя хуже из-за большей чувствительности; Используемая 384D модель ```paraphrase-multilingual-MiniLM-L12-v2```в целом ведет себя адекватно; Возможно модель промежуточной размерности могла бы дать налучшие результаты
- Изменения состава метаданных (на примере "отравленных" данных было видно, что модель низко оценивает "ценные", но редко встречающиеся данные)
- Использование стратегии гибридного (семантический + ключевые слова) поиска
- Оптимизации параметров поиска (стратегия, метрика, порог релевантности, удаление дублирующихся данных, проверка орфографии)