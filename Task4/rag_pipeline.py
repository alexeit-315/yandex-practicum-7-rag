#!/usr/bin/env python3
"""
RAG –ø–∞–π–ø–ª–∞–π–Ω —Å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM —á–µ—Ä–µ–∑ Ollama
"""

import chromadb
from sentence_transformers import SentenceTransformer
from typing import List, Dict
import time

from config import config
from prompts import build_rasa_prompt, get_response_template
from llm_client import LLMClient


class RAGPipeline:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM"""
        print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG –ø–∞–π–ø–ª–∞–π–Ω–∞...")

        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        self.embed_model = SentenceTransformer(config.EMBEDDING_MODEL)
        print(f"   ‚úÖ –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {config.EMBEDDING_MODEL}")

        # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î
        self.client = chromadb.PersistentClient(path=config.VECTOR_DB_PATH)
        self.collection = self.client.get_collection(config.COLLECTION_NAME)
        print(f"   ‚úÖ –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î –ø–æ–¥–∫–ª—é—á–µ–Ω–∞: {self.collection.count()} —á–∞–Ω–∫–æ–≤")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM
        self.llm_client = LLMClient(model=config.LLM_MODEL)
        print("   ‚úÖ LLM –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def retrieve_chunks(self, query: str, n_results: int = None) -> Dict:
        """–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤"""
        if n_results is None:
            n_results = config.SEARCH_RESULTS_COUNT

        try:
            query_embedding = self.embed_model.encode([query]).tolist()
            results = self.collection.query(
                query_embeddings=query_embedding,
                n_results=n_results,
                include=["documents", "metadatas", "distances"]
            )
            return results
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —á–∞–Ω–∫–æ–≤: {e}")
            return {"documents": [], "metadatas": [], "distances": []}

    def is_relevant(self, distances: List[float]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        if not distances:
            return False
        return min(distances) <= config.RELEVANCE_THRESHOLD

    def prepare_prompt(self, query: str, context_chunks: List[str]) -> str:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è LLM"""
        return build_rasa_prompt(
            question=query,
            context_chunks=context_chunks,
            use_cot=config.ENABLE_CHAIN_OF_THOUGHT
        )

    def generate_response(self, query: str, context_chunks: List[str]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—É—é LLM"""
        if not context_chunks:
            return "ü§∑ –í –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å"

        prompt = self.prepare_prompt(query, context_chunks)

        print("üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM...")
        start_time = time.time()

        response = self.llm_client.generate(prompt)

        duration = time.time() - start_time
        print(f"   ‚úÖ –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∑–∞ {duration:.2f} —Å–µ–∫")

        return response

    def fallback_response(self, query: str, context_chunks: List[str]) -> str:
        """–ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –æ—Ç–≤–µ—Ç–∞"""
        if not context_chunks:
            return "ü§∑ –Ø –Ω–µ –∑–Ω–∞—é –æ—Ç–≤–µ—Ç –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å"

        main_answer = context_chunks[0]
        if len(main_answer) > 300:
            main_answer = main_answer[:300] + "..."

        template = get_response_template("general")
        return template.format(answer=main_answer)

    def process_query(self, query: str) -> str:
        """–ü–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞"""
        print(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: '{query}'")

        results = self.retrieve_chunks(query)

        if not results or not results.get("documents") or not results["documents"][0]:
            return "ü§∑ –ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"

        distances = results.get("distances", [[]])[0]
        if not self.is_relevant(distances):
            return "ü§∑ –Ø –Ω–µ –∑–Ω–∞—é –æ—Ç–≤–µ—Ç –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å"

        try:
            return self.generate_response(query, results["documents"][0])
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ LLM, fallback: {e}")
            return self.fallback_response(query, results["documents"][0])


# –°–∏–Ω–≥–ª—Ç–æ–Ω —ç–∫–∑–µ–º–ø–ª—è—Ä
rag_pipeline = RAGPipeline()
